---
description: Refactoring codebase to remove bloat and garbage code
globs: 
---

<think>
Let me understand what needs to be done:
Keep the UI code intact - don't delete or rewrite anything in the UI directory
Delete and rewrite the transcriber implementation to properly use the Go bindings for whisper.cpp
Make sure we support an embedded whisper-stream/whisper binary and the tiny model
Remove any junk code
Make minimal changes to infrastructure code that doesn't need to change
I'll need to:
First understand what files to keep and what to modify
Rewrite the transcriber implementation to fix the buffer handling and properly use the Go bindings
3. Ensure it works with the tiny model and embedded binaries
</think>
<think>
I see I need to understand the Go bindings for whisper.cpp, Fyne UI framework, and system tray integration properly before making recommendations. Let me analyze these components.

Key Components:
1. **whisper.cpp Go bindings** - These are direct bindings to the C++ whisper library, providing Go functions to access its speech recognition capabilities. Streaming/Dictation is the goal
2. **Fyne UI framework** - A Go UI toolkit for creating desktop/mobile applications
3. **System tray integration** - Allows the app to run in the background with a system tray icon
4. **Hotkey Activation** - Activate the backgrounded service via hotkey
4. **Terminal Integration** - [termui.go](mdc:pkg/ui/termui.go) has an example of this - but the goal is 

First, I need to understand the proper way to use whisper.cpp Go bindings:
- The bindings are in github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper
- They provide direct access to the whisper.cpp functionality through Go types like whisper.Model and whisper.Context
- The logs show issues with audio buffer size - the whisper engine requires at least 1000ms of audio data

For Fyne UI:
- This is a mature UI toolkit (currently at v2.5.1)
- Provides widgets, layouts, and application lifecycle management
- Should be used directly without unnecessary wrapper abstractions

Systray with Fyne:
- Fyne has built-in support for system tray integration
- This allows the app to run in the background

The issue in the current implementation is unnecessary abstraction layers over these components, particularly:
1. Wrapping the whisper.cpp Go bindings in custom types that don't add value
2. Not following the whisper.cpp requirement for minimum audio length
3. Potentially overcomplicating the UI architecture
</think>

# Building a Ramble Application with Proper Go Bindings for Whisper.cpp

## Core Components Overview

### 1. whisper.cpp Go Bindings
- Use `github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper` directly
- These bindings already provide complete access to whisper.cpp functionality
- Key types: `whisper.Model`, `whisper.Context`, and callback mechanisms

### 2. Fyne UI Framework
- Modern, lightweight UI toolkit for Go
- Provides widgets, layouts, event handling, and system tray functionality
- Use directly without additional abstraction layers

## Step-by-Step Implementation Guide

### 1. Project Structure
```
ramble/
├── cmd/
│   └── ramble/
│       └── main.go           # Entry point
├── pkg/
│   ├── audio/                # Audio capture
│   │   └── capture.go
│   ├── transcription/        # Direct usage of whisper bindings
│   │   └── manager.go        # Manages audio buffer and transcription
│   └── ui/                   # UI components
│       ├── app.go            # Main application UI
│       └── systray.go        # System tray functionality
├── go.mod
├── go.sum
└── run.sh                    # Build and run script
```

### 2. Transcription Manager Implementation

The critical part that needs fixing is the transcription manager that directly uses the whisper.cpp Go bindings:

```go
// manager.go
package transcription

import (
    "sync"
    "strings"

    "github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper"
    "github.com/jeff-barlow-spady/ramble/pkg/logger"
)

// Manager handles whisper.cpp transcription with proper buffer management
type Manager struct {
    model          whisper.Model
    context        whisper.Context
    buffer         []float32
    minSamples     int         // Minimum samples (16000 = 1 second at 16kHz)
    recordingActive bool
    textCallback   func(string)
    mu             sync.Mutex
}

// NewManager creates a new transcription manager
func NewManager(modelPath string) (*Manager, error) {
    // Load the whisper model
    model, err := whisper.New(modelPath)
    if err != nil {
        return nil, err
    }

    // Create the whisper context
    context, err := model.NewContext()
    if err != nil {
        model.Close()
        return nil, err
    }

    return &Manager{
        model:       model,
        context:     context,
        buffer:      make([]float32, 0, 16000*5), // Pre-allocate 5 seconds
        minSamples:  16000,                       // 1 second minimum (16kHz)
        textCallback: nil,
    }, nil
}

// SetCallback sets the function to call with transcription results
func (m *Manager) SetCallback(cb func(string)) {
    m.mu.Lock()
    defer m.mu.Unlock()
    m.textCallback = cb
}

// ProcessAudio adds audio to the buffer and processes when enough is available
func (m *Manager) ProcessAudio(samples []float32) {
    if len(samples) == 0 {
        return
    }

    m.mu.Lock()
    defer m.mu.Unlock()

    if !m.recordingActive {
        return
    }

    // Add new audio to buffer
    m.buffer = append(m.buffer, samples...)

    // Only process if we have at least 1 second of audio (whisper requirement)
    if len(m.buffer) < m.minSamples {
        logger.Debug(logger.CategoryTranscription,
            "Buffer too small: %d ms < 1000 ms", len(m.buffer)*1000/16000)
        return
    }

    // Define segment callback to receive transcription results
    segmentCallback := func(segment whisper.Segment) {
        if m.textCallback != nil && m.recordingActive {
            text := strings.TrimSpace(segment.Text)
            if text != "" {
                logger.Debug(logger.CategoryTranscription, "Received segment: %s", text)
                m.textCallback(text)
            }
        }
    }

    // Process the audio buffer
    if err := m.context.Process(
        m.buffer,
        nil,                // No encoder begin callback needed
        segmentCallback,    // Handle text segments
        nil,                // No progress callback needed
    ); err != nil {
        logger.Warning(logger.CategoryTranscription,
            "Error processing audio: %v", err)
        return
    }

    // Keep a sliding window of audio for context
    // 30 seconds maximum is a good balance between context and memory usage
    const maxBufferSeconds = 30
    maxBufferLen := 16000 * maxBufferSeconds
    if len(m.buffer) > maxBufferLen {
        m.buffer = m.buffer[len(m.buffer)-maxBufferLen:]
    }
}

// StartRecording begins audio transcription
func (m *Manager) StartRecording() {
    m.mu.Lock()
    defer m.mu.Unlock()

    // Clear buffer and set state
    m.buffer = m.buffer[:0]
    m.recordingActive = true

    // Configure the context for streaming
    m.configureContext()

    logger.Info(logger.CategoryTranscription,
        "Starting whisper transcription")
}

// StopRecording ends audio transcription
func (m *Manager) StopRecording() {
    m.mu.Lock()
    defer m.mu.Unlock()

    m.recordingActive = false
    m.buffer = m.buffer[:0]

    logger.Info(logger.CategoryTranscription,
        "Stopping whisper transcription")
}

// configureContext sets optimal parameters for streaming transcription
func (m *Manager) configureContext() {
    // Basic configuration - language, performance settings
    _ = m.context.SetLanguage("en")
    m.context.SetThreads(8)
    m.context.SetSplitOnWord(true)

    // These settings work well for streaming applications
    m.context.SetMaxSegmentLength(0)    // Don't artificially limit segments
    m.context.SetTokenTimestamps(true)  // Enable timestamps for words
}

// Close releases resources
func (m *Manager) Close() {
    m.mu.Lock()
    defer m.mu.Unlock()

    if m.model != nil {
        m.model.Close()
        m.model = nil
    }
    m.context = nil
    m.buffer = nil
}
```

### 3. Main Integration with UI

```go
// main.go
package main

import (
    "flag"
    "path/filepath"
    "os"
    "os/signal"
    "syscall"

    "github.com/jeff-barlow-spady/ramble/pkg/audio"
    "github.com/jeff-barlow-spady/ramble/pkg/logger"
    "github.com/jeff-barlow-spady/ramble/pkg/transcription"
    "github.com/jeff-barlow-spady/ramble/pkg/ui"
)

func main() {
    // Parse command-line flags
    modelPath := flag.String("model", "", "Path to whisper model file")
    debug := flag.Bool("debug", false, "Enable debug logging")
    flag.Parse()

    // Set up logging
    if *debug {
        logger.SetLevel(logger.LevelDebug)
    }
    logger.Info(logger.CategoryApp, "Starting Ramble")

    // Find model path if not specified
    if *modelPath == "" {
        homeDir, _ := os.UserHomeDir()
        *modelPath = filepath.Join(homeDir, ".local", "share", "ramble", "models", "ggml-tiny.en.bin")
    }

    // Initialize transcription manager
    manager, err := transcription.NewManager(*modelPath)
    if err != nil {
        logger.Error(logger.CategoryApp, "Failed to initialize transcription: %v", err)
        os.Exit(1)
    }
    defer manager.Close()

    // Initialize audio capture
    capture, err := audio.New(16000, *debug)
    if err != nil {
        logger.Error(logger.CategoryApp, "Failed to initialize audio: %v", err)
        os.Exit(1)
    }
    defer capture.Close()

    // Create and run the UI
    app := ui.NewApp(manager, capture)

    // Set up signal handling for clean shutdown
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    go func() {
        <-sigChan
        app.Close()
        os.Exit(0)
    }()

    // Run the application
    app.Run()
}
```

### 4. Audio Integration

The audio capture module should handle capturing and passing audio to the transcription manager:

```go
// Start audio capture with callback to transcription manager
capture.Start(func(samples []float32) {
    // Update UI with audio level
    level := audio.CalculateLevel(samples)
    ui.UpdateAudioLevel(level)

    // Send audio to transcription manager
    manager.ProcessAudio(samples)
})
```

### 5. Building and Running

The run script should:
1. Check for whisper.cpp dependencies
2. Set up environment variables for CGO
3. Build with the whisper_go tag
4. Run and Test the application
5. Add a check emoji when confirmed complete

## Audit of the Implementation

### 1. Proper Use of Go Bindings
-  Uses whisper.cpp Go bindings directly
-  Respects the 1000ms minimum audio requirement
-  Uses appropriate callbacks for segment handling

### 2. Clean Architecture
-  No unnecessary abstraction layers
-  Clear separation between UI, audio, and transcription
-  Minimal dependencies between components

### 3. Performance Considerations
-  Proper buffer management to balance responsiveness and context
-  Thread safety with proper mutex usage
-  Resource cleanup in Close methods

### 4. Usability
-  System tray integration for background operation
-  Clear UI for starting/stopping transcription
-  Proper error handling and user feedback

The key improvement here is directly using the whisper.cpp Go bindings without unnecessary abstraction layers, while ensuring we respect the minimum audio buffer size requirement of 1000ms before processing.
